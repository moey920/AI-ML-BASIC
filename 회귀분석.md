# 회귀분석(Linear Regression)

기계학습 - 지도학습 - 회귀분석

## 단순선형회귀분석(Simple Linear Regression)

- 회귀분석이란?

대학 운동부 학생들의 신체검사 자료, 신입생 A가 들어왔다.(키는 175cm이다) 예상 몸무게는 얼마인가?   
-> 추세선(Regression)을 따라 175cm의 몸무게를 보았을 떄 65kg인 것을 예측할 수 있다.

## 회귀분석법

당신은 엘리스의 데이터 사이언티스트다.   

- 데이터: 광고 분석과 판매량
- 목표: FB 광고에 얼마를 투자하면… 상품이 얼마나 팔릴까?
- 방법: 데이터를 가장 잘 설명하는 어떤 선을 하나 찾는다.

### 변수 표기
- N : 데이터의 개수
- X : Input; 데이터/Feature “광고료”
- Y : Output; 해답/응답 “판매량”
- (x(i), y(i)): i번째 데이터

`판매량 (천개) : Y축`   
`광고료 (만원) : X축`

### 문제 정의

- 데이터: N개의 FB 광고 예산(X)과 판매량(Y)
- 목표: 광고에 얼마를 투자했을 때 얼마나 팔릴까?

`광고 예산 > 학습된 모델 > 판매량` : X -> Y

- 가정: TV 광고 예산과 판매량은 선형적 관계를 가진다 `Y ~ B0X + B1` B0 = a(기울기), B1 = b(절편)
- 문제: 어떤 β0, β1이 좋은 것인가?

#### 기울기와 절편 실습

```
# 실습에 필요한 패키지입니다. 수정하지 마세요.
import elice_utils
import matplotlib as mpl
mpl.use("Agg")
import matplotlib.pyplot as plt
import numpy as np
eu = elice_utils.EliceUtils()

# 실습에 필요한 데이터입니다. 수정하지마세요. 
X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]
Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]

'''
beta_0과 beta_1 을 변경하면서 그래프에 표시되는 선을 확인해 봅니다.
기울기와 절편의 의미를 이해합니다.
'''

# 이 선을 자동으로 찾는 것이 회귀 분석이다.
beta_0 = 0.67   # beta_0에 저장된 기울기 값을 조정해보세요. 
beta_1 = 1 # beta_1에 저장된 절편 값을 조정해보세요.

plt.scatter(X, Y) # (x, y) 점을 그립니다.
plt.plot([0, 10], [beta_1, 10 * beta_0 + beta_1], c='r') # y = beta_0 * x + beta_1 에 해당하는 선을 그립니다.

plt.xlim(0, 10) # 그래프의 X축을 설정합니다.
plt.ylim(0, 10) # 그래프의 Y축을 설정합니다.

# 엘리스에 이미지를 표시합니다.
plt.savefig("test.png")
eu.send_image("test.png")
```

### 모델의 학습 목표

- 아이디어: 완벽한 예측은 불가능하다. 각 데이터 (x(i), y(i)) 의 실제 값과 모델이 예측하는 값을 최소한으로 하자!

- i번째 데이터(x(i), y(i)) 에 대해 :
    - 실제 값 : y(i)
    - 예측 값 : B0x(i) + B1
    - 차이 : y(i) - (B0x(i) + B1)
    - 전체 모델의 차이: sum(y(i) - (B0x(i) + B1))
        - 반례 : 두 점을 예측한 값의 오차의 합이 0이 될 수 있다. (양수와 음수의 차이) 나쁜 선을 그었음에도 좋다고 판단될 수 있다.
            - 그래서 오차의 제곱, 오차의 평균등의 방법을 쓰는 것이다.
            - sum((y(i) - (B0x(i) + B1))^2)

### 문제 재정의

- 전체 모델의 차이 : sum((y(i) - (B0x(i) + B1))^2) : “Loss function” = L(B0, B1)
    - 이 차이를 최소로 하는 β0, β1 을 구하자.
    - argmin((y(i) - (B0x(i) + B1))^2)


#### Loss function 실제로 구현해보기

```
import elice_utils
import matplotlib as mpl
mpl.use("Agg")
import matplotlib.pyplot as plt
import numpy as np
eu = elice_utils.EliceUtils()

def loss(x, y, beta_0, beta_1):
    '''
    x, y, beta_0, beta_1 을 이용해 loss값을 계산한 뒤 리턴합니다.
    '''

    N = len(x) # 10
    # 수식을 파이썬 코드로 변환하기
    # 파이썬 array 이용한 방법
    '''
    total_loss = 0 # i가 n일 때 loss값을 더하기 위한 값
    for i in range(N) : # 수식 sum을 변환
        y_i = y[i] # 실제 y(i)
        x_i = x[i] # 실제 x(i)
        y_predicted = beta_0 * x_i + beta_1
        
        # 실제값과 예측값의 오차의 제곱
        diff = (y_i - y_predicted) ** 2
        total_loss += diff
        
    return total_loss
    '''
    
    # Numpy array를 이용해 간단하게 만드는 방법
    x = np.array(x) # 넘파이 형식으로 변경
    y = np.array(y)
    
    # 이번엔 x가 스칼라값이 아니고 numpy의 array이다.(벡터의 모든 자원에 스칼라곱)
    y_predicted = beta_0 * x + beta_1
    
    total_loss = np.sum((y - y_predicted) ** 2)
    
    return total_loss
    

X = [8.70153760, 3.90825773, 1.89362433, 3.28730045, 7.39333004, 2.98984649, 2.25757240, 9.84450732, 9.94589513, 5.48321616]
Y = [5.64413093, 3.75876583, 3.87233310, 4.40990425, 6.43845020, 4.02827829, 2.26105955, 7.15768995, 6.29097441, 5.19692852]

beta_0 = 1 # 기울기
beta_1 = 0.5 # 절편

print("Loss: %f" % loss(X, Y, beta_0, beta_1))

plt.scatter(X, Y) # (x, y) 점을 그립니다.
plt.plot([0, 10], [beta_1, 10 * beta_0 + beta_1], c='r') # y = beta_0 * x + beta_1 에 해당하는 선을 그립니다.

plt.xlim(0, 10) # 그래프의 X축을 설정합니다.
plt.ylim(0, 10) # 그래프의 Y축을 설정합니다.
plt.savefig("test.png") # 저장 후 엘리스에 이미지를 표시합니다.
eu.send_image("test.png")
```

## 산 정상 오르기

산 정상이 되는 지점을 찾고 싶다. 아무 곳에서나 시작했을 때, 가장 정상을 빠르게 찾아가는 방법은?   

가정
- 정상의 위치는 알 수 없다.
- 현재 나의 위치와 높이를 알 수 있다.
- 내 위치에서 일정 수준 이동할 수 있다.
21
산 정상 오르기
방법
- 현재 위치에서 가장 경사가 높은 쪽
을 찾는다.
- 오르막 방향으로 일정 수준 이동한다.
- 더 이상 높이의 변화가 없을 때까지 반복!
산 정상이 되는 지점을 찾고 싶다.
아무 곳에서나 시작했을 때, 가장 정상을 빠르게 찾아가는 방법은?
22
거꾸로 된 산을 내려가기
데이터를 가장 잘 설명하는 β0, β1을 구하자
= 예측 값과 실제 값의 차이를 최소로 만드는 값을 구하자
= Loss function을 최소로 만드는 β0, β1을 구하자
L(0, 1) = X
N
i
(y(i)  (0x(i) + 1))2
23
거꾸로 된 산을 내려가기
L(0, 1) = X
N
i
(y(i)  (0x(i) + 1))2
24
실습 3: Scikit-learn을
이용한 회귀분석
Module 4: 다중회귀분석
인공지능/머신러닝 기초
26
다중회귀분석
Multiple Linear Regression
27
데이터가 조금 더 복잡하다면?
엘리스에서 FB광고뿐만 아니라 TV 및 신문 광고도 하기로 결정했다.
이제 여러분은 각 매체가 얼마나 효율적인지 알아내야 한다.
FB TV 신문 판매량
FB에 44.5만원,
TV에 39.3만원,
신문에 45.1만원을
집행했을 때
10,400 건의 판매를
기록했다.
28
다중회귀분석
문제: FB에 30만원, TV에 100만원, 신문에 50만원의
광고비를 집행했을 때 예상 판매량은 얼마인가?
FB TV 신문 판매량
FB에 44.5만원,
TV에 39.3만원,
신문에 45.1만원을
집행했을 때
10,400 건의 판매를
기록했다.
29
Notation
N: 데이터의 개수 FB TV 신문 판매량
X: “Input” 데이터/Feature (광고료)
 - X1: FB 광고료
 - X2: TV 광고료
 - X3: 신문 광고료
Y: “Output” 해답/응답 (판매량)
(x1(i), x2(i), x3(i), y(i)): i번째 데이터
30
문제 정의
데이터: N개의 FB, TV, 신문 광고 예산과 판매량
X1 Y
FB TV 신문 판매량
X2 X3
광고 예산 학습된 모델 판매량
목표: FB, TV, 신문에 각각 얼마씩을 투자했을 때
 얼마나 팔릴까?
가설: 학습 알고리즘이 주어진 데이터를 학습
31
문제 정의
가정: 판매량은 FB, TV, 신문 광고료와 선형적 관계
X1 X2 X3 Y
FB TV 신문 판매량
Y ⇠ 0X1 + 1X2 + 2X3 + 3
광고 예산 학습된 모델 판매량
데이터: N개의 FB, TV, 신문 광고 예산과 판매량
목표: FB, TV, 신문에 각각 얼마씩을 투자했을 때
 얼마나 팔릴까?
32
모델의 학습 목표
단순선형회귀분석과 동일
완벽한 예측은 불가능하다.
각 데이터 (x1(i), x2(i), x3(i), y(i)) 의 실제 값과
모델이 예측하는 값을 최소한으로 하자!
푸는 방법도 동일
Y ⇠ 0X1 + 1X2 + 2X3 + 3
Y ⇠ 0X1 + 1X2 + 2X3 + 3
33
수학적으로 다시 쓰기
실제 값: y(i)
0x(i)
1 + 1x(i)
2 + 2x(i) 모델이 예측한 값: 3 + 3
(y(i)  (0x(i)
1 + 1x(i)
2 + 2x(i)
3 + 3))2 차이의 제곱:
차이의 제곱의 합: X
N
i
(y(i)  (0x(i)
1 + 1x(i)
2 + 2x(i)
3 + 3))2
= Loss function
이 차이를 최소로 하는 β0, β1, β2, β3 을 구하자.
34
Demo: 다중회귀분석
35
다항식 회귀분석
Polynomial Linear Regression
36
더 좋은 방법
단순한 선형회귀법은 데이터를 잘 설명하지 못한다.
조금 더 데이터에 맞게 모델을 학습시킬 수 없을까?
37
다항식 회귀분석
문제: 판매량과 광고비의 관계를 2차식으로 표현해 보자.
광고비 판매량
Y = 0X2 + 1X + 2
선형관계가 아닌데
어떻게 문제를 풀지?
38
다항식 회귀분석
문제: 판매량과 광고비의 관계를 2차식으로 표현해 보자.
광고비 판매량
Y = 0X2 + 1X + 2
X1 = X2
X2 = X
로 치환하면…
Y = 0X1 + 1X2 + 2
다중회귀분석과 동일해진다
52946.01
1980.25
295.84
22952.25
32688.64
75.69
3306.25
…
X1 X2
광고비2
39
숙제: 다항식 회귀분석
academy.elice.io
contact@elice.io
facebook.com/elice.io
blog.naver.com/elicer
